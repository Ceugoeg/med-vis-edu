为了咱们这套系统能丝滑落地，我把咱们俩负责的模块和对应的配合动作理清楚了。你看看这套连招顺不顺手：

模块一：一键归位 (握拳 = 聚合) 🤜🤛
这步的核心就是把炸开的零件收回来，重新拼成一颗完整的心脏。

我这边负责 (A)： 兄弟放心，我会死盯着摄像头的 MediaPipe 数据。只要我看到那四个指尖全缩回去了（相对于指根 y 轴偏移极小），我就立刻往咱们全局的 window.handData 里塞一个 state: 'FIST'。

你那边配合 (C)： 你只要一监听到 FIST 状态，就赶紧拉满你的 animateExplode(factor) 函数，把 factor 顺滑地降到 0。这时候心脏必须完美合拢，系统无缝切到 WHOLE（整体检视）状态。

模块二：盘它！ (保持握拳滑动 = 360度全方位检视) 🌍
这时候用户的手就是个物理轨迹球，捏着心脏转。

我这边负责 (A)： 我会持续稳稳地给你输出 state: 'FIST' 状态。而且你放宽心，传给你的那 21 个关键点 landmarks 坐标，我都加了一阶滞后滤波处理过了，手部的物理抖动我帮你扛了，绝对不让模型得帕金森！

你那边配合 (C)： 你一拿到 FIST，立马记下那一瞬间的屏幕二维坐标当锚点。用户滑动的时候，你就用相对位移（Delta X/Y）来实时控 pivotGroup 的旋转矩阵。千万别用绝对坐标硬射，不然视角跳变太辣眼睛了。

💡 体验加分项： 哥们，商量个事，用户松手的时候（脱离 FIST），你根据最后的滑动速度给模型加点物理摩擦力（Damping）让它自己再缓缓转一下停住呗？那手感绝对爽飞！

模块三：原力炸开，但别飞瞎 (张开手掌 = 散开检视) 🖐️
这个模块不仅要炸开，还得炸得“恰到好处”，不能让零件飞出屏幕外。

我这边负责 (A)： 只要用户手指全张开，各关节角度一过我设的阈值，我就果断给你发 state: 'OPEN'。

你那边配合 (C)： 收到指令，你就把 animateExplode(factor) 向 1 过渡，模型切到 SCATTERED（散开抓取）状态。

⚠️ 核心约束重点： 这里是重头戏！你得用 THREE.Box3 动态算一下所有散开零件的“全局包围盒”。拿它跟相机的视锥体（Frustum）实时对一下，在数学上卡死最大爆炸系数，保证左右心室这种边缘零件绝对不超出屏幕！对了，这状态下必须把全局旋转给我锁死，不然咱们下一步没法瞄准了。

模块四：精准手术镊 (瞄准后捏合 = 零件特写 + AI 讲解) 🤏
在散开的场景里，精准地把一块特定的肉“拉”到眼前学习。

我这边负责 (A)： 在手掌张开的基线上，只要食指（点 8）和拇指（点 4）捏一起了（我听劝，不用 0.05 的绝对值，我搞个基于手掌比例的动态阈值，远近都能捏），我就判定为捏合，发 state: 'PINCH'。

你那边配合 (C)： 收到 PINCH 的下降沿，你立马发射射线（Raycaster）去捞模型。要是捞中了（比如命中了 Heart_LV），马上切 FOCUSED（单体聚焦特写）状态。

👀 视觉与 UI 响应： 接下来看你的了！用 THREE.Box3 算出这块肉的真实“几何中心”对齐世界原点，再顺带自适应调一下相机 Z 轴焦距给个完美特写。然后赶紧拿着 query 字段去呼叫 DeepMed API，在侧边栏把医学知识刷出来（要是 API 卡了，老规矩，先上 LocalCache 里的预置文本顶一下）。